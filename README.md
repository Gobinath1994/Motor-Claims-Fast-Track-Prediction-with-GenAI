
# ğŸš— Motor Claims Fast-Track Prediction with GenAI

This repository provides a complete end-to-end machine learning and GenAI pipeline to predict whether a motor insurance claim should be fast-tracked. It includes raw data ingestion, preprocessing, NLP-based feature engineering, ensemble feature selection, model training & evaluation, and a live Streamlit dashboard powered by Amazon Bedrock's Mistral 7B.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ 01_data_ingestion_to_rds.py         # Load raw claims data into AWS RDS
â”œâ”€â”€ 02_data_cleaning_pipeline.py        # Clean and preprocess claims
â”œâ”€â”€ 03_data_exploration_pipeline.ipynb  # Visual data exploration and profiling
â”œâ”€â”€ 04_feature_engineering_pipeline.py  # Add domain features, TF-IDF, embeddings, PCA, KMeans
â”œâ”€â”€ 05_feature_selection_pipeline.py    # Select top features using ensemble techniques
â”œâ”€â”€ 06_model_training_pipeline.py       # Train, tune and evaluate ML models
â”œâ”€â”€ 07_selected_features_dump.py        # Save selected features list to disk
â”œâ”€â”€ 08_fasttrack_dashboard_genai.py     # Streamlit dashboard for prediction and GenAI reasoning
â”œâ”€â”€ models/                             # Stores trained models and transformers
â”œâ”€â”€ requirements.txt                    # Python dependencies
â””â”€â”€ README.md                           # Project documentation
```

---

## ğŸš€ Local Execution Guide (End-to-End)

### 1ï¸âƒ£ Create Conda Environment

```bash
conda create -p env_Motor_Claim python=3.11 -y
conda activate /Users/gobinathsindhuja/Suncorp_task/env_Motor_Claim
pip install -r requirements.txt
```

### 2ï¸âƒ£ Configure AWS RDS Connection

Update MySQL RDS credentials in scripts that use:

```python
sqlalchemy.create_engine("mysql+pymysql://<user>:<password>@<host>/<db>")
```

### 3ï¸âƒ£ Run the Data + Modeling Pipeline in Order

```bash
python Scripts/01_data_ingestion_to_rds.py
python Scripts/02_data_cleaning_pipeline.py
python Scripts/04_feature_engineering_pipeline.py
python Scripts/05_feature_selection_pipeline.py
python Scripts/06_model_training_pipeline.py
python Scripts/07_selected_features_dump.py
```

### 4ï¸âƒ£ Launch Streamlit Dashboard (Locally)

```bash
streamlit run Scripts/08_fasttrack_dashboard_genai.py
```

Access: http://localhost:8501

---

## ğŸ§  GenAI Integration (Amazon Bedrock - Mistral 7B)

The dashboard connects to Amazon Bedrock to generate:

- ğŸ“‹ Executive Claim Summary  
- âš ï¸ Risk Tags  
- ğŸ’¡ Next-Step Recommendation

### Setup Instructions

```bash
aws configure
```

Or set credentials in `~/.aws/credentials`.

Required permission: `bedrock:InvokeModel`

---

## â˜ï¸ EC2 Deployment Instructions

### 1ï¸âƒ£ Launch EC2 Instance

- Choose Ubuntu 22.04 LTS
- Open ports: `22` (SSH) and `8501` (Streamlit)

### 2ï¸âƒ£ SSH into EC2

```bash
chmod 400 Motor_claim_key.pem
ssh -i Motor_claim_key.pem ubuntu@<ec2-public-ip>
```

### 3ï¸âƒ£ Install Requirements on EC2

```bash
sudo apt update && sudo apt install -y python3-pip git docker.io
pip install --upgrade pip
pip install -r requirements.txt
```

### 4ï¸âƒ£ Transfer Project Files from Local

```bash
scp -i Motor_claim_key.pem -r ./models ubuntu@<ec2-ip>:~/aws_fasttrack_dashboard/
scp -i Motor_claim_key.pem *.py requirements.txt ubuntu@<ec2-ip>:~/aws_fasttrack_dashboard/
```

### 5ï¸âƒ£ Run Streamlit App on EC2

```bash
cd ~/aws_fasttrack_dashboard
streamlit run 08_fasttrack_dashboard_genai.py --server.port 8501 --server.enableCORS false
```

Then visit: http://<your-ec2-ip>:8501

---

## ğŸ“¦ Output

- âœ… CSV with predictions, probabilities, LLM summaries and tags
- âœ… Records stored in AWS RDS (`motor_claims_predictions`)
- âœ… Visual dashboard with SHAP insights and GenAI explanations

---

## ğŸ§ª Techniques Used

- SMOTE Oversampling for class imbalance
- PCA for dimensionality reduction
- KMeans clustering on embeddings
- Sentence-BERT (MiniLM) for semantic text features
- TF-IDF for sparse textual features
- Ensemble feature voting (MI, Boruta, LGBM, L1 Logistic)
- Model tuning using Optuna
- Explainability via SHAP
- Amazon Bedrock for LLM summarization and tagging

---

## ğŸ›¡ï¸ .gitignore Setup

To avoid uploading unnecessary data or environment artifacts, use:

```
# Ignore raw data and sensitive files
data/
*.csv
*.xlsx
*.docx

# Model outputs and logs
catboost_info/
*.joblib
*.pkl
*.png

# Python envs
env_*/
__pycache__/
.ipynb_checkpoints/

# AWS credentials
*.pem
```

---

## ğŸ“¬ Author

**Gobinath Subramain**  
Email: g.subramani@uqconnect.edu.au
Use Case: Automating motor claims triage using ML + GenAI   
