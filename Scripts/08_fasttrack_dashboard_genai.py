# -----------------------------------------------------------------------------------------------
# ğŸ§¾ File: streamlit_dashboard.py
# ğŸ“Œ Purpose: Streamlit-based interactive dashboard for fast-track motor claims prediction,
#             risk tagging, and Amazon Bedrock GenAI summary generation.
#             This top section loads models, sets up AWS + RDS connections, and imports modules.
# -----------------------------------------------------------------------------------------------

# âœ… Core Streamlit Web App framework
import streamlit as st

# âœ… Data processing libraries
import pandas as pd                          # For working with tabular data (DataFrames)
import numpy as np                          # For numerical operations

# âœ… ML & Vectorization utilities
import joblib                               # For loading serialized models and transformers
import json, re, time, random               # Built-in libraries: parsing, regex, delays, randomness

# âœ… AWS integration for GenAI and model inference
import boto3                                # AWS SDK (used here for calling Bedrock)

# âœ… Database support
import sqlalchemy                           # ORM and SQL connection (used here for AWS RDS)

# âœ… Visualization
import plotly.express as px                 # For interactive visualizations in the dashboard

# âœ… Date/time management
from datetime import datetime               # Used for timestamping records

# âœ… Text embeddings model
from sentence_transformers import SentenceTransformer  # For converting text into embeddings

# âœ… Scalers
from sklearn.preprocessing import MinMaxScaler  # For feature scaling (if needed in preprocessing)

# -----------------------------------------------------------------------------------------------
# ğŸ¯ Load ML and NLP artifacts saved during training
# -----------------------------------------------------------------------------------------------

# ğŸ” Main classifier model (e.g., RandomForest or XGBoost)
model = joblib.load("models/best_model.pkl")

# ğŸ§  Pre-trained TF-IDF vectorizer for converting descriptions to sparse text features
tfidf = joblib.load("models/tfidf_vectorizer.joblib")

# ğŸ”„ PCA transformer used to reduce dimensionality of embeddings
pca = joblib.load("models/pca_transformer.joblib")

# ğŸ“Š KMeans clustering model for segmenting similar damage descriptions
kmeans = joblib.load("models/kmeans_cluster.joblib")

# ğŸ”§ Feature scaler used during model training for normalization
scaler = joblib.load("models/scaler.pkl")

# ğŸ“‹ Final list of selected features after feature selection pipeline
selected_features = joblib.load("models/selected_features.pkl")

# ğŸ”¤ Sentence-level embedding model (MiniLM) for dense semantic understanding
embedder = SentenceTransformer("all-MiniLM-L6-v2")

# -----------------------------------------------------------------------------------------------
# ğŸŒ©ï¸ Set up Amazon Bedrock runtime client
# Used for GenAI inference (Mistral 7B in production) â€” summaries, tags, recommendations.
# -----------------------------------------------------------------------------------------------
bedrock = boto3.client("bedrock-runtime", region_name="ap-southeast-2")

# -----------------------------------------------------------------------------------------------
# ğŸ›¢ï¸ AWS RDS database connection (MySQL)
# Used to load or save batch claims, predictions, summaries, and logs.
# -----------------------------------------------------------------------------------------------
rds_uri = (
    "mysql+pymysql://admin:mExmuk-kitqim-jodza9@"
    "suncorp.ct2ykcc82vni.ap-southeast-2.rds.amazonaws.com/Suncorp"
)
engine = sqlalchemy.create_engine(rds_uri)
# ---------------------------------------------------------------------------------------------------- #
# ğŸ”§ Function: feature_engineering(df)
# ğŸ“Œ Purpose: Apply domain-specific, statistical, text-based, and interaction-based transformations
#     to enrich the input claims data before feeding it into the trained model.
# ğŸ“¥ Input:
#     df (pd.DataFrame): Raw claims DataFrame uploaded via the UI or read from database.
# ğŸ“¤ Output:
#     df (pd.DataFrame): Enhanced DataFrame with all engineered features ready for prediction.
# ---------------------------------------------------------------------------------------------------- #
def feature_engineering(df):
    # ----------------------- Numerical Transformations -----------------------
    
    # Calculate vehicle age based on the assumption it's 2025 now
    df["vehicle_age"] = 2025 - df["vehicle_year"]
    
    # Derive average mileage per year to normalize usage
    df["mileage_per_year"] = df["vehicle_mileage"] / df["vehicle_age"].replace(0, 1)
    
    # Flag if mileage is unusually high (possible old or frequently used vehicle)
    df["high_mileage_flag"] = (df["vehicle_mileage"] > 150000).astype(int)
    
    # Log-transform mileage for better model learning (reduce skew)
    df["log_mileage"] = np.log1p(df["vehicle_mileage"])

    # ----------------------- Customer Profile Features -----------------------

    # Claims filed per year of being a customer â€” proxy for claim frequency
    df["prior_claim_rate"] = df["historical_claims_count"] / df["customer_tenure"].replace(0, 1)
    
    # Flag if customer has made >1 past claim â€” potentially risky
    df["is_high_claim_history"] = (df["historical_claims_count"] > 1).astype(int)
    
    # Group tenure into bins to reduce granularity
    df["tenure_group"] = pd.cut(df["customer_tenure"], bins=[0, 2, 5, 10, 20], labels=["<2y", "2-5y", "5-10y", "10+y"])
    
    # Loyalty indicator if customer tenure > 7 years
    df["is_loyal_customer"] = (df["customer_tenure"] > 7).astype(int)
    
    # Log-transform tenure to reduce skew
    df["log_tenure"] = np.log1p(df["customer_tenure"])

    # ----------------------- Text Description Features -----------------------

    # Calculate number of words in damage description
    df["desc_length"] = df["damage_description"].str.split().apply(len)
    
    # Flag short descriptions (which may be low-effort or less detailed)
    df["low_effort_text"] = (df["desc_length"] < 12).astype(int)

    # Manually crafted keyword features based on domain knowledge
    keywords = {
        "has_safety_keywords": ["fluid", "leaks", "alignment", "safety", "confirmed", "concern"],
        "mentions_minor": ["minor", "scuff", "surface", "bending"]
    }

    # Search for each keyword in the damage_description column
    for colname, terms in keywords.items():
        df[colname] = df["damage_description"].apply(
            lambda x: int(any(re.search(rf"\b{term}\b", str(x).lower()) for term in terms))
        )

    # ----------------------- TF-IDF Vectorization -----------------------

    # Transform text using pre-trained TF-IDF vectorizer
    tfidf_matrix = tfidf.transform(df["damage_description"])
    
    # Convert sparse matrix to dense DataFrame
    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f"tfidf_{t}" for t in tfidf.get_feature_names_out()])
    
    # Merge TF-IDF features back to original data
    df = pd.concat([df.reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)

    # ----------------------- Sentence Embeddings -----------------------

    # Use pre-loaded MiniLM model to encode text as dense embeddings
    embeddings = embedder.encode(df["damage_description"].tolist(), show_progress_bar=False)
    
    # Convert embeddings into DataFrame
    emb_df = pd.DataFrame(embeddings, columns=[f"text_emb_{i}" for i in range(embeddings.shape[1])])
    
    # Append embedding features to main DataFrame
    df = pd.concat([df.reset_index(drop=True), emb_df], axis=1)

    # ----------------------- PCA Reduction on Embeddings -----------------------

    # Reduce high-dimensional embeddings into 5 principal components
    pca_comps = pca.transform(embeddings)
    for i in range(pca_comps.shape[1]):
        df[f"text_pca_{i+1}"] = pca_comps[:, i]

    # ----------------------- Clustering -----------------------

    # Predict semantic cluster using pre-trained KMeans
    df["text_cluster"] = kmeans.predict(embeddings)

    # ----------------------- Binary & Interaction Flags -----------------------

    # Convert severe damage into binary flag
    df["is_severe_damage"] = (df["damage_level_reported"] == "Severe").astype(int)
    
    # Convert garage_estimate_provided from boolean to int
    df["is_garage_provided"] = df["garage_estimate_provided"].astype(int)

    # Create logical interaction between severity and estimate
    df["est_provided_x_severity"] = df["is_garage_provided"] * df["is_severe_damage"]
    
    # Combine age and mileage to detect wear/tear risks
    df["vehicle_age_x_mileage"] = df["vehicle_age"] * df["mileage_per_year"]
    
    # Combine delay and severity to capture urgency
    df["claim_delay_x_severity"] = df["days_between_accident_and_claim"] * df["is_severe_damage"]

    # Combine loyalty and prior claims to model risk over time
    df["tenure_x_claim_rate"] = df["customer_tenure"] * df["prior_claim_rate"]

    # Flag claims that were delayed more than 2 weeks
    df["delay_flag"] = (df["days_between_accident_and_claim"] > 14).astype(int)

    # ----------------------- Domain Risk Scoring -----------------------

    # Heuristic-based scoring: high risk if more severe, delayed, or history of many claims
    df["risk_score_proxy"] = (
        df["is_severe_damage"] * 3 +
        df["is_high_claim_history"] * 2 +
        df["delay_flag"] +
        df["has_safety_keywords"]
    )

    # âœ… Return enhanced DataFrame
    return df

# ------------------------------------------------------------------------------------------------
# ğŸ¤– GenAI Summarization & Reasoning via Amazon Bedrock (Mistral 7B)
# ------------------------------------------------------------------------------------------------

def invoke_bedrock(prompt, max_retries=3):
    """
    Calls the Amazon Bedrock Mistral model with a given prompt and handles throttling retries.

    Parameters:
        prompt (str): Instruction text to send to the Mistral model (e.g., claim summary request).
        max_retries (int): Number of retry attempts if throttled (default: 3).

    Returns:
        str: The generated response from the Mistral model, or an error message if failed.
    """
    for attempt in range(max_retries):
        try:
            # ğŸ” Send the prompt to Amazon Bedrock's Mistral 7B model
            response = bedrock.invoke_model(
                modelId="mistral.mistral-7b-instruct-v0:2",  # âœ… Mistral 7B via Bedrock
                contentType="application/json",              # ğŸ“¤ Input format
                accept="application/json",                   # ğŸ“¥ Output format
                body=json.dumps({
                    "prompt": prompt,                        # ğŸ§  Text instruction to the model
                    "max_tokens": 512,                       # âœ‚ï¸ Max tokens in output
                    "temperature": 0.3                       # ğŸ² Lower value = more deterministic
                })
            )

            # ğŸ“¦ Read and decode JSON response
            output = json.loads(response["body"].read())
            
            # âœ… Return the first generated output
            return output["outputs"][0]["text"]

        except Exception as e:
            # ğŸ”„ If rate-limited (ThrottlingException), wait and retry
            if "ThrottlingException" in str(e):
                time.sleep(random.uniform(1.5, 3.0))  # â±ï¸ Backoff between 1.5â€“3.0s
            else:
                # âŒ Return error message for other exceptions
                return f"âŒ Error: {str(e)}"
    
    # âŒ If all retries fail
    return "âŒ Max retries reached"

def get_genai_outputs(record):
    """
    Generates three GenAI outputs for a given motor insurance claim record:
    1. Executive claim summary
    2. Risk tags
    3. Recommended next action

    Parameters:
        record (dict): A single claim record (row) as a dictionary after preprocessing.

    Returns:
        summary (str): A business-readable summary of the claim.
        tags (str): A short list of 3 risk-related tags.
        next_step (str): A single next-step recommendation for the claim.
    """
    # ğŸ“„ Convert dictionary record to formatted JSON string
    record_json = json.dumps(record, indent=2)

    # ğŸ§  Build base prompt context for all queries
    base_prompt = f"Summarise the following motor insurance claim:\n{record_json}\n"

    # 1ï¸âƒ£ Generate claim summary + explanation of fast-track reason
    summary = invoke_bedrock(base_prompt + "\nWhy is it fast-tracked or not?")

    # 2ï¸âƒ£ Generate short risk factor tags (for display or analysis)
    tags = invoke_bedrock(base_prompt + "\nGive 3 short risk factor tags for this claim.")

    # 3ï¸âƒ£ Generate recommended next step action (e.g., inspection, payout, etc.)
    next_step = invoke_bedrock(base_prompt + "\nSuggest one next step action for this claim.")

    # âœ… Return all outputs
    return summary, tags, next_step

# ------------------------------------------------------------------------------------------------
# ğŸ“Š Streamlit Dashboard UI â€“ Fast-Track Claim Predictor with GenAI Summaries
# ------------------------------------------------------------------------------------------------

# ğŸŒ Set Streamlit page configuration (title and layout)
st.set_page_config(page_title="ğŸš— Fast-Track Claim Predictor", layout="wide")

# ğŸ·ï¸ Title of the application (centered, with HTML formatting)
st.markdown("<h1 style='text-align:center;'>ğŸš— Motor Claims Fast-Track Predictor</h1>", unsafe_allow_html=True)

# Horizontal line separator
st.markdown("<hr>", unsafe_allow_html=True)

# ğŸ“¤ CSV Upload section for users to input raw claims
uploaded = st.file_uploader("ğŸ“¤ Upload motor claims CSV", type="csv")

# ------------------------------------------------------------------------------------------
# ğŸ“ Once file is uploaded, begin processing pipeline
# ------------------------------------------------------------------------------------------
if uploaded:
    # ğŸ§¾ Load CSV file into DataFrame
    raw = pd.read_csv(uploaded)

    # â„¹ï¸ Notify user that feature engineering has started
    st.info("ğŸ”„ Running Feature Engineering...")

    # âš™ï¸ Apply domain + NLP + vectorization transformations
    processed = feature_engineering(raw.copy())

    # âœ… Notify completion of feature pipeline
    st.success("âœ… Feature Engineering Complete")

    # ğŸ§ª Select and scale only the chosen features
    X = processed[selected_features]
    X_scaled = scaler.transform(X)

    # ğŸ¤– Run classification model to generate predictions and probabilities
    preds = model.predict(X_scaled)
    probs = model.predict_proba(X_scaled)[:, 1]

    # ğŸ“Š Append predictions and timestamp to raw DataFrame
    raw["fast_track_prediction"] = preds                         # Binary class (0 or 1)
    raw["confidence_score"] = probs.round(4)                     # Probability score (0â€“1)
    raw["timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")  # Timestamp of prediction

    # âœ… Notify that ML predictions are completed
    st.success("âœ… Predictions Complete")

    # --------------------------------------------------------------------------------------
    # ğŸ§  GenAI Integration: Generate claim summaries, risk tags, and next steps
    # --------------------------------------------------------------------------------------
    st.info("ğŸ§  Generating LLM Summaries + Tags + Next Steps...")

    summaries, tags, steps = [], [], []

    # ğŸ” Loop over each record to invoke GenAI for insights
    for i, row in raw.iterrows():
        summary, tag, step = get_genai_outputs(row.to_dict())  # ğŸ¤– Prompt Bedrock
        summaries.append(summary)
        tags.append(tag)
        steps.append(step)
        time.sleep(1)  # ğŸ’¤ Small delay to avoid throttling Bedrock API

    # ğŸ§¾ Append GenAI columns to raw DataFrame
    raw["genai_summary"] = summaries       # ğŸ“„ Executive summary of claim
    raw["risk_tags"] = tags                # ğŸ·ï¸ Risk factor tags
    raw["next_step"] = steps               # ğŸš¦ Recommended action

    # âœ… Notify that GenAI tasks are completed
    st.success("ğŸ§  GenAI Processing Done")

    # --------------------------------------------------------------------------------------
    # ğŸ“Š Dashboard Metrics + Class Distribution Chart
    # --------------------------------------------------------------------------------------
    col1, col2 = st.columns(2)

    with col1:
        # ğŸ“¦ Total records and Fast-track counts
        st.metric("ğŸ“¦ Total Claims", len(raw))
        st.metric("âœ… Fast-Tracked", (raw["fast_track_prediction"] == 1).sum())

    with col2:
        # ğŸ“Š Bar chart: Distribution of prediction classes
        chart_df = raw["fast_track_prediction"].value_counts().reset_index()
        chart_df.columns = ["Prediction", "Count"]
        fig = px.bar(
            chart_df,
            x="Prediction",
            y="Count",
            color=chart_df["Prediction"].astype(str),
            title="Fast-Track Class Distribution"
        )
        st.plotly_chart(fig, use_container_width=True)

    # --------------------------------------------------------------------------------------
    # ğŸ“‹ Results Table + Download Button
    # --------------------------------------------------------------------------------------
    st.dataframe(raw.head(10))  # ğŸ‘ï¸ Show first 10 rows in preview

    # ğŸ“¥ Allow users to download full predictions
    st.download_button(
        "ğŸ“¥ Download Full Output",
        raw.to_csv(index=False),
        file_name="predictions_with_summary.csv"
    )

    # --------------------------------------------------------------------------------------
    # ğŸ’¾ Save Results to Database (MySQL RDS)
    # --------------------------------------------------------------------------------------
    try:
        raw.to_sql("motor_claims_predictions", con=engine, if_exists="append", index=False)
        st.success("ğŸ’¾ Results saved to database successfully.")
    except Exception as e:
        st.error(f"âŒ DB Save Failed: {str(e)}")

    # --------------------------------------------------------------------------------------
    # ğŸ“Š Executive Batch Summary using LLM (Optional)
    # --------------------------------------------------------------------------------------
    st.subheader("ğŸ“Š Executive Batch Summary")

    # Use GenAI to generate a batch summary over the top 20 claims
    batch_summary = invoke_bedrock(
        f"Summarise this batch of motor insurance predictions:\n{raw.head(20).to_dict(orient='records')}"
    )
    st.markdown(batch_summary)

    # --------------------------------------------------------------------------------------
    # ğŸ“Š Dashboard Visual Overview Section
    # Shows multiple charts to help users interpret prediction results across dimensions.
    # --------------------------------------------------------------------------------------

    # ğŸ”¹ Horizontal divider
    st.markdown("---")

    # ğŸ“¢ Section header
    st.subheader("ğŸ“Š Visual Overview of Prediction Results")

    # Make a copy of the full dataset (with predictions and probabilities)
    view_df = raw.copy()

    # --------------------------------------------------------------------------------------
    # 1ï¸âƒ£ Fast-Track Prediction Distribution (Bar Chart)
    # --------------------------------------------------------------------------------------

    # âœ… Count how many claims are classified as fast-tracked (1) vs not (0)
    prediction_counts = view_df["fast_track_prediction"].value_counts().reset_index()
    prediction_counts.columns = ["Prediction", "Count"]

    # ğŸ“Š Bar chart to show binary classification results
    fig1 = px.bar(
        prediction_counts,
        x="Prediction",
        y="Count",
        color="Prediction",
        title="âœ… Fast-Track Prediction Distribution"
    )
    st.plotly_chart(fig1, use_container_width=True)

    # --------------------------------------------------------------------------------------
    # 2ï¸âƒ£ Confidence Score Distribution (Pie Chart)
    # --------------------------------------------------------------------------------------

    # ğŸ“ˆ Bin probability scores into categories: Low, Medium, High, Very High
    conf_bins = pd.cut(
        view_df["confidence_score"],
        bins=[0, 0.5, 0.7, 0.85, 1],
        labels=["Low", "Medium", "High", "Very High"]
    )

    # ğŸ”¢ Count how many predictions fall in each confidence band
    conf_counts = conf_bins.value_counts().reset_index()
    conf_counts.columns = ["Confidence Level", "Count"]

    # ğŸ¥§ Pie chart to visualize confidence level distribution
    fig2 = px.pie(
        conf_counts,
        names="Confidence Level",
        values="Count",
        title="ğŸ“ Confidence Score Distribution"
    )
    st.plotly_chart(fig2, use_container_width=True)

    # --------------------------------------------------------------------------------------
    # 3ï¸âƒ£ Vehicle Year vs Prediction (Box Plot)
    # --------------------------------------------------------------------------------------

    # ğŸ“¦ Box plot to visualize relationship between vehicle year and fast-track label
    fig4 = px.box(
        view_df,
        x="fast_track_prediction",
        y="vehicle_year",
        points="all",  # Show outliers and data points
        title="ğŸš˜ Vehicle Year vs Prediction"
    )
    st.plotly_chart(fig4, use_container_width=True)

    # --------------------------------------------------------------------------------------
    # 4ï¸âƒ£ Accident Location Type vs Prediction (Grouped Bar Chart)
    # --------------------------------------------------------------------------------------

    # ğŸ“ If location type data exists, show breakdown by accident location type
    if "accident_location_type" in view_df.columns:
        # ğŸ“Š Count number of predictions for each location type + fast-track combo
        grouped = view_df.groupby(
            ["accident_location_type", "fast_track_prediction"]
        ).size().reset_index(name="count")

        # ğŸ§± Grouped bar chart for each location type and prediction class
        fig5 = px.bar(
            grouped,
            x="accident_location_type",
            y="count",
            color="fast_track_prediction",
            barmode="group",
            title="ğŸ“ Location Type vs Prediction"
        )
        st.plotly_chart(fig5, use_container_width=True)